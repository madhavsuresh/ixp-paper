\documentclass{acm_proc_article-sp}

\begin{document}

\title{Determining Remote Peerings at IXPs}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Mario Sanchez\\
       \affaddr{Northwestern University}\\
       \affaddr{EECS Department}\\
       \affaddr{Evanston, IL}\\
       \email{msanchez@northwestern.edu}
% 2nd. author
\alignauthor
Madhav Suresh\\
       \affaddr{Northwestern University}\\
       \affaddr{EECS Department}\\
       \affaddr{Evanston, IL}\\
       \email{madhav@u.northwestern.edu}
}
\date{16 March 2012}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Peering matrices of Internet exchange points (IXPs) have been an area of interest because of their
critical role in the flow of traffic. \cite{Augustin:2009}
Remote peering at IXPs has been a recent trend, as it allows smaller ASs to bypass more costly 
peering agreements.
Efforts have been made to discover peering matrices at IXPs however no work has been done 
to discover remote peers. We designed and implemented a tool that can determine remote peerings
given a peering list of an IXP. Using traceroutes obtained from Dasu \cite{Sanchez:2011}, geolocation
techniques and reverse dns, we were able to determine remote peerings with 
%TODO: 
(WHAT?) level of accuracy.
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

%\terms{IXP, remote peering}

%\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings

\section{Introduction}

\section{System Design}

The work described in this paper is a first step towards full Checkpoint and Restore functionality. As a result the scope of this project is limited in two major ways:
\begin{description}
\item[Device and timer state is not preserved.]\hfill\\
This is a severe limitation and we propose a solution in Section~\ref{sec:future}.
\item[Only ``stop-the-world'' checkpointing is supported.]\hfill\\
Live migration is postponed for a future project.
\end{description}

For now we also impose the following restrictions. However, as explained in the comments below, these simplifications do not fundamentally change the nature of the problem we are solving:
\begin{description}
\item[The guest is single-core.]\hfill\\
Checkpoint and Restore of multi-core guests should only require minor changes to the implementation of single-core Checkpoint and Restore.
\item[The guest has less than 64 MB of memory.]\hfill\\
Handling guests with more memory does not pose new challenges in principle but requires more careful handling of the host memory that contains the checkpoint.
\item[Palacios is embedded in a Linux host.]\hfill\\
Since the Checkpoint and Restore logic is in the OS-independent portion of Palacios, supporting other host systems should be straightforward.
\item[Only AMD SVM \cite{SVM} virtualization is supported.]\hfill\\
Adding support for Intel VT-x \cite{VTX} should be a simple modification to the support for SVM.
\item[The checkpoint is kept in memory.]\hfill\\
For practical use the checkpoint should be persisted (e.g. to a file), however the technical challenges are no different from those of an in-memory checkpoint.
\end{description}

\section{Usage}
Checkpoint and Restore functionality is made available to users of Palacios through control scripts on the host OS. The term ``Restore'' is a bit misleading in the current implementation, since the checkpointed guest is actually copied into a new guest. A more appropriate description might be ``Checkpoint and Clone''.

A typical workflow is illustrated in the example below, which presumes familiarity with the Linux embedding of Palacios. All commands are run on the host OS.

In order to support development of Checkpoint and Restore we added control scripts for pausing and resuming a guest, which are also illustrated below.

\begin{verbatim}
# v3_ctrl guest_os.img src
\end{verbatim}
This creates a new guest VM named ``src'' from the file \verb,guest_os.img,. For the purposes of this example we will assume the guest image is assigned the device \verb,/dev/v3-vm0,.

\begin{verbatim}
# v3_pause /dev/v3-vm0
\end{verbatim}
Pauses (suspends) execution of the guest that is mapped to \verb,/dev/v3-vm0,.

\begin{verbatim}
# v3_resume /dev/v3-m0
\end{verbatim}
Resumes execution of the guest at \verb,/dev/v3-vm0,, assuming it is currently paused.

\begin{verbatim}
# v3_checkpoint /dev/v3-vm0
\end{verbatim}
This causes a checkpoint to be taken of the guest mapped to \verb,/dev/v3-vm0,, which must be executing when \verb,v3_checkpoint, is called. The checkpointed state is stored in kernel memory. As a side effect, this command causes guest execution to be paused as though \verb,v3_pause, was called.

\begin{verbatim}
# v3_clone guest_os.img /dev/v3-vm0 dest
\end{verbatim}
This causes a new guest vm to be created as a clone of the guest mapped to \verb,/dev/v3-vm0,. \verb,v3_clone, assumes that a checkpoint has already been taken of the guest that will be cloned. The clone will be named ``dest''. Since we use an ``Initialize and Patch'' strategy (see Section~\ref{sec:approach}), the original configuration file must also be passed to \verb,v3_clone,.
In our current implementation the new guest begins execution immediately.

\section{Approach}
\label{sec:approach}

\section{Issues}
We were able to implement pause, resume and checkpoint successfully. Cloning however causes the guest to halt, and 
we were unable to find the bug. 
Given the time constraint of a quarter, there were many things we simply did not have time for.
For now, the checkpoint data for a guest is stored in a fixed size buffer that is stored locally to the VM. Each
VM can only save one checkpoint as newer checkpoints overwrite previous ones. In the future we plan to save
the checkpoint data to disk. The state of the devices is not saved. Multicore guests are not supported in pause,resume,checkpoint or resume.

\section{Asynchronous State}
Each VM has a operating mode state enumerated by operating\_mode. The states are generally set by a signal
from the host operating system. They are then checked in the code paths where the guest is executed.
An example of where the state is asnychronously set and used is for VM\_STOPPED.
We added two more states (VM\_PAUSED, VM\_PAUSING)to v3\_core\_operating\_mode\_t to facilitate pause/ resume.
For checkpointing, four states are added to a new type v3\_ checkpoint\_ mode\_t, CHECKPOINT\_NONE, CHECKPOINT\_ PENDING, 
CHECKPOINT\_DONE, CHECKPOINT\_FAILED. This will be covered in detail in the checkpoint section

\section{Pause and Resume}
Pausing a VM means the obvious; the execution of the guest must stop. In order to do this, the guest cannot be scheduled
until a resume signal is sent. This is done by preventing an svm launch from occuring. When the VM is created, every core 
enters an event loop that checks the state of the machine and then enters into handling svm specific code (this is where 
the svm launch occurs). Before the svm enter occurs, the state is checked. If it is VM\_PAUSING, the state is set to VM\_PAUSED
and then the core spins until the state is set otherwise.
VM\_PAUSING, if it has 
When a VM is created a thread is created that is an event loop which handles vm exits (HOW TO DESCRIBE EVENT LOOP?).

\section{Checkpoint/Restore}
The state of a machine is essentially the registers and the memory. For a VM, the state is the state of the machine
plus the palacios datastructures. So in order to properly checkpoint/restore, the registers, memory and vm state must be saved.
A new data structure was added to v3\_vm\_info to keep track of the checkpoint information. This
struct contained a buffer where the data from the checkpoint would be saved, and a state to determine whether the 
machine was intended to be checkpointed. The four new states are: CHECKPOINT\_NONE, CHECKPOINT\_PENDING, 
CHECKPOINT\_DONE, CHECKPOINT\_FAILED. The purpose of the first and last state are obvious, while CHECKPOINT\_PENDING and
CHECKPOINT\_DONE are used so that the caller of can be notified of completion the checkpoint.

\subsection{Saving Checkpoint Data}
The state flag to check if a checkpoint should occur is inside a critical section inside of v3\_svm\_enter. The check is done
inside the critical section so that way the state cannot be altered during the copy.
The memory of the guest is a continuguous physical region on the host, so it is simply memcpy'd into the checkpoint buffer.
All of the registers of the vm are saved, as well as the per core info struct, guest\_info and the VMCB. 
The guest\_info per core struct is the only palacios data structure that is saved upon checkpoint, this is because
the other data structures can be created from the config file that is created in v3\_start\_guest

\subsection{Restoring Checkpoint Data}
Currently, a restore from a checkpoint happens when a v3\_clone is called. The clone is essentially an extension
on creating a new VM, the only difference is that the saved state is copied over during the initilization after 
the configuration is parsed. *** EXPAND ON THIS There are some key things that are not overwritten because during this copy: namely cr3

\section{Control Interface}
The v3\_ctrl interface provided the perfect means to send the signal to the VM to checkpoint/restore.
It allows the user to asynchronously send and recieve information to the VMM. 
The interface operates by sending ioctls on the the VMM or the appropriate VM.
The palacios VMM and every VM are devices in the linux host and can be access from user space via ioctls.
We added v3\_resume, v3\_pause, v3\_checkpoint, and v3\_clone. 
\subsection{v3\_pause,v3\_checkpoint,v3\_resume}
As discussed above, pausing, resuming and checkpointing only require a signal from the user. This is because 
these events are triggered by state changes in the guest. Through the v3\_ctrl interface we send the device an ioctl
with the appropriate number, which was then handled by the Linux kernel. Linux then passes the intent to the VMM which
handles the state change. All of the ioctls are called on VMs since these actions change only change the state of a VM.

\subsection{v3\_clone}
The v3\_clone interface is a little more complicated because it needs to get the pointer to the checkpoint buffer
of the guest it's cloning. It is is also the only ctrl that ioctls the VMM. This is because it needs the VMM to create a new
virtual machine. 

\section{Implementation Challenges}
Initially we thought that the entire v3\_vm\_info struct had to be copied. Then we realized everything could
be gotten from the config... I don't know what to write here.

\section{Future Work}
\label{sec:future}
Much to do.

\bibliographystyle{abbrv}
\bibliography{ixp}

\end{document}
